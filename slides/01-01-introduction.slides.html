<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="dcterms.date" content="2021-01-21">
  <title>Introduction</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
  <link rel="stylesheet" href="../assets/css/talks.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG" type="text/javascript"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    TeX: {
         extensions: ["color.js"]
      }
    });
  </script>
  <script src="../assets/js/figure-animate.js"></script>
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Introduction</h1>
  <p class="author" style="text-align:center"><a href="http://inverseprobability.com">Neil D. Lawrence</a></p>
  <p class="date" style="text-align:center"><time>2021-01-21</time></p>
  <p class="venue" style="text-align:center">Computer Laboratory, William Gates Building, 15 J. J. Thomson Avenue</p>
</section>

<section class="slide level2">

<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
</section>
<section id="course-overview" class="slide level2">
<h2>Course Overview</h2>
</section>
<section id="section" class="slide level2">
<h2></h2>
<div class="figure">
<div id="nyu-deep-learning-figure" class="figure-frame">
<iframe width="800" height="600" src="https://www.youtube.com/embed/0bMe_vCZo30?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
</div>
<aside class="notes">
Lecture from the NYU course on Deep Learning given by Yann LeCun, Alfredo Canziani and Mark Goldstein
</aside>
</section>
<section id="lecturers" class="slide level2">
<h2>Lecturers</h2>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip0">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Ferenc Huszar
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="../slides/diagrams/people/ferenc-huszar.jpg" clip-path="url(#clip0)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip1">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Nic Lane
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="../slides/diagrams/people/nic-lane.jpg" clip-path="url(#clip1)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip2">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Neil Lawrence
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="../slides/diagrams/people/neil-lawrence.png" clip-path="url(#clip2)"/>
</svg>
</div>
</section>
<section id="schedule" class="slide level2">
<h2>Schedule</h2>
<ul>
<li>Week 1:
<ol type="1">
<li>Introduction and Data. Lecturer: <a href="http://inverseprobability.com/">Neil D. Lawrence</a></li>
<li>Generalisation and Neural Networks. Lectuer: <a href="http://inverseprobability.com/">Neil D. Lawrence</a></li>
</ol></li>
<li>Week 2:
<ol type="1">
<li>Automatic Differentiation. Lecturer: <a href="https://www.inference.vc/about/">Ferenc Huszár</a></li>
<li>Optimization and Stochastic Gradient Descent. Lecturer: <a href="https://www.inference.vc/about/">Ferenc Huszár</a></li>
</ol></li>
</ul>
</section>
<section id="schedule-1" class="slide level2">
<h2>Schedule</h2>
<ul>
<li>Week 3:
<ol type="1">
<li>Hardware. Lecturer: <a href="http://niclane.org/">Nic Lane</a></li>
<li>Summary and Gap Filling: <a href="https://www.inference.vc/about/">Ferenc Huszár</a>, <a href="http://inverseprobability.com/">Neil D. Lawrence</a>, <a href="http://niclane.org/">Nic Lane</a></li>
</ol></li>
</ul>
<p><strong>Set Assignment 1 (30%)</strong></p>
</section>
<section id="schedule-2" class="slide level2">
<h2>Schedule</h2>
<ul>
<li>Week 4:
<ol type="1">
<li>Convolutional Neural Networks: <a href="http://niclane.org/">Nic Lane</a>, <a href="https://www.inference.vc/about/">Ferenc Huszár</a></li>
<li>Recurrent Neural Networks: <a href="http://niclane.org/">Nic Lane</a>, <a href="https://www.inference.vc/about/">Ferenc Huszár</a></li>
</ol></li>
</ul>
<p><strong>Assignment 1 Submitted</strong></p>
</section>
<section id="schedule-3" class="slide level2">
<h2>Schedule</h2>
<ul>
<li>Week 5:
<ol type="1">
<li>Sequence to Sequence and Attention: <a href="https://www.inference.vc/about/">Ferenc Huszár</a></li>
<li>Transformers: <a href="https://www.inference.vc/about/">Ferenc Huszár</a></li>
</ol></li>
</ul>
<p><strong>Set Assignment 2 (70%)</strong></p>
</section>
<section id="special-topics" class="slide level2">
<h2>Special Topics</h2>
<ul>
<li>Weeks 6-8
<ul>
<li>Guest lectures from Ferenc, Nic and Neil</li>
<li>Guest lectures from external speakers
<ul>
<li>(e.g. Raia Hadsell on 11th March).</li>
</ul></li>
</ul></li>
</ul>
<!-- SECTION What is Machine Learning? -->
</section>
<section id="what-is-machine-learning" class="slide level2">
<h2>What is Machine Learning?</h2>
</section>
<section id="what-is-machine-learning-1" class="slide level2">
<h2>What is Machine Learning?</h2>
<div class="fragment">
<p><span class="math display">\[ \text{data} + \text{model} \stackrel{\text{compute}}{\rightarrow} \text{prediction}\]</span></p>
</div>
<div class="fragment">
<ul>
<li><strong>data</strong> : observations, could be actively or passively acquired (meta-data).</li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>model</strong> : assumptions, based on previous experience (other data! transfer learning etc), or beliefs about the regularities of the universe. Inductive bias.</li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>prediction</strong> : an action to be taken or a categorization or a quality score.</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Royal Society Report: <a href="https://royalsociety.org/~/media/policy/projects/machine-learning/publications/machine-learning-report.pdf">Machine Learning: Power and Promise of Computers that Learn by Example</a></li>
</ul>
</div>
</section>
<section id="what-is-machine-learning-2" class="slide level2">
<h2>What is Machine Learning?</h2>
<p><span class="math display">\[\text{data} + \text{model} \stackrel{\text{compute}}{\rightarrow} \text{prediction}\]</span></p>
<ul>
<li class="fragment">To combine data with a model need:</li>
<li class="fragment"><strong>a prediction function</strong> <span class="math inline">\(f(\cdot)\)</span> includes our beliefs about the regularities of the universe</li>
<li class="fragment"><strong>an objective function</strong> <span class="math inline">\(E(\cdot)\)</span> defines the cost of misprediction.</li>
</ul>
</section>
<section id="ingredients" class="slide level2">
<h2>Ingredients</h2>
</section>
<section id="cybernetics-neural-networks-and-the-ratio-club" class="slide level2">
<h2>Cybernetics, Neural Networks and the Ratio Club</h2>
</section>
<section id="logic-mcculloch-and-pitts" class="slide level2">
<h2>Logic, McCulloch and Pitts</h2>
<div class="figure">
<div id="russell-pitts-mcculloch-figure" class="figure-frame">
<table>
<tr>
<td width="30%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/philosophy/Bertrand_Russell_1957.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="30%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ml/Lettvin_Pitts.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="30%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ml/warren_mcculloch.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
</div>
<aside class="notes">
Bertrand Russell (1872-1970), Walter Pitts, <em>right</em> (1923-1969), Warren McCulloch (1898-1969)
</aside>
</section>
<section id="cybernetics" class="slide level2">
<h2>Cybernetics</h2>
<div class="figure">
<div id="maxwell-gibbs-wiener-figure" class="figure-frame">
<table>
<tr>
<td width="30%">
<div class="centered" style="">
<img class="" src="../slides/diagrams/physics/james-clerk-maxwell.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="30%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/physics/j-w-gibbs.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="30%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/physics/Norbert_wiener.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
</div>
<aside class="notes">
James Clerk Maxwell (1831-1879), Josiah Willard Gibbs (1839-1903), Norbert Wiener (1894-1964)
</aside>
</section>
<section id="analogue-and-digital" class="slide level2">
<h2>Analogue and Digital</h2>
<div class="figure">
<div id="donald-maccrimmon-mackay-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/physics/dmaccrimmonmackay.jpg" width="30%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Donald M. MacKay (1922-1987), an early member of the Cybernetics community and member of the Ratio Club.
</aside>
</section>
<section id="the-perceptron" class="slide level2">
<h2>The Perceptron</h2>
<div class="figure">
<div id="ashby-neumann-rosenblatt-figure" class="figure-frame">
<table>
<tr>
<td width="30%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ml/w-ross-ashby.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="30%">
<div class="centered" style="">
<img class="" src="../slides/diagrams/physics/JohnvonNeumann-LosAlamos.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="30%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/Frank_Rosenblatt.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
</div>
<aside class="notes">
W. Ross Ashby (1903-1972), John von Neumann (1903-1957), Frank Rosenblatt (1928-1971). <em>Photograph of W. Ross Ashby is Copyright W. Ross Ashby</em>.
</aside>
</section>
<section id="the-connectionists" class="slide level2">
<h2>The Connectionists</h2>
<div class="figure">
<div id="-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ml/connectionist-summer-school.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Group photo from the 1986 Connectionists’ Summer School, held at CMU in July. Included in the photo are Richard Durbin, Terry Sejnowski, Geoff Hinton, Yann LeCun, Michael I. Jordan.
</aside>
</section>
<section id="section-1" class="slide level2">
<h2></h2>
<div class="figure">
<div id="pdp-volume-1-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ml/pdp_cover.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Cover of the Parallel Distributed Processing edited volume <span class="citation" data-cites="Rumelhart:book86">(Rumelhart et al., 1986)</span>.
</aside>
<aside class="notes">
What makes people smarter than computers? These volumes by a pioneering neurocomputing group suggest that the answer lies in the massively parallel architecture of the human mind. They describe a new theory of cognition called connectionism that is challenging the idea of symbolic computation that has traditionally been at the center of debate in theoretical discussions about the mind.
</aside>
</section>
<section id="section-2" class="slide level2">
<h2></h2>
<div class="figure">
<div id="nc-cover-lecun-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ml/nc_cover.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Cover of <em>Neural Computation</em>, Volume 1, Issue 4 containing <span class="citation" data-cites="LeCun:zip89">Le Cun et al. (1989)</span>. The cover shows examples from the U.S. Postal Service data set of handwritten digits.
</aside>
<aside class="notes">
The first several stages of processing in our previous system (described in Denker et al. 1989) involved convolutions in which the coefficients had been laboriously hand designed. In the present system, the first two layers of the network are constrained to be convolutional, but the system automatically learns the coefficients that make up the kernels.
</aside>
<!--include{_ml/includes/what-does-machine-learning-do.md}-->
</section>
<section id="section-3" class="slide level2">
<h2></h2>
<div class="figure">
<div id="neil-newton-institute-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/people/1997-08-02-neil-newton-institute.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Neil standing outside the Newton Institute on 2nd August 1997, just after arriving for “Generalisation in Neural Networks and Machine Learning”, <a href="http://www.newton.ac.uk/files/reports/annual/ini_annual_report_97-98.pdf">see page 26-30 of this report</a>.
</aside>
</section>
<section id="section-4" class="slide level2">
<h2></h2>
<div class="figure">
<div id="le-net-5-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ml/le-net-5.gif" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Gif animation of LeNet-5 in action.
</aside>
</section>
<section id="section-5" class="slide level2">
<h2></h2>
<div class="figure">
<div id="le-net-5-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ml/le-net-translate.gif" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Gif animation of LeNet-5 in action. Here the translation invariance of the network is being tested.
</aside>
</section>
<section id="section-6" class="slide level2">
<h2></h2>
<div class="figure">
<div id="le-net-5-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ml/le-net-scale.gif" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Gif animation of LeNet-5 in action, here the scale invariance of the network is being tested.
</aside>
</section>
<section id="section-7" class="slide level2">
<h2></h2>
<div class="figure">
<div id="cortes-guyon-vapnik-figure" class="figure-frame">
<table>
<tr>
<td width="30%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ml/corinna-cortes.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="30%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ml/isabelle-guyon.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="30%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/ml/vladmir-vapnik.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
</div>
<aside class="notes">
Corinna Cortes, Isabelle Guyon and Vladmir Vapnik. Three of the key people behind the support vector machine <span class="citation" data-cites="Boser-optimal92">(Boser et al., 1992, p. @Cortes:svnet95)</span>. All were based at Bell Labs in the 1990s.
</aside>
</section>
<section id="section-8" class="slide level2">
<h2></h2>
<blockquote>
<p>This work points out the necessity of having flexible “network design” software tools that ease the design of complex, specialized network architectures</p>
<p>From conclusions of <span class="citation" data-cites="LeCun:zip89">Le Cun et al. (1989)</span></p>
</blockquote>
</section>
<section id="section-9" class="slide level2">
<h2></h2>
<div class="figure">
<div id="russakovsky-li-figure" class="figure-frame">
<table>
<tr>
<td width="50%">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ml/olga-russakovsky.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="50%">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ml/fei-fei-li.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
</div>
<aside class="notes">
Olga Russakovsky, Fei Fei Li. Olga and Fei Fei led the creation of the ImageNet database that enabled convolutional neural networks to show their true potential. The data base contains millions of images.
</aside>
</section>
<section id="the-third-wave" class="slide level2">
<h2>The Third Wave</h2>
<ul>
<li>Data (many data, many classes)</li>
<li>Compute (GPUs)</li>
<li>Stochastic Gradient Descent</li>
<li>Software (autograd)</li>
</ul>
</section>
<section id="domains-of-use" class="slide level2">
<h2>Domains of Use</h2>
<ul>
<li>Perception and Representation
<ol type="1">
<li>Speech</li>
<li>Vision</li>
<li>Language</li>
</ol></li>
</ul>
</section>
<section id="experience" class="slide level2">
<h2>Experience</h2>
<ul>
<li>Bringing it together:
<ul>
<li>Unsupervised pre-training</li>
<li>Initialisation and RELU</li>
<li>A Zoo of methods and models</li>
</ul></li>
</ul>
<ul>
<li>Why do they generalize well?</li>
</ul>
</section>
<section id="conclusion" class="slide level2">
<h2>Conclusion</h2>
<ul>
<li>Understand the principles behind:
<ul>
<li>Generalization</li>
<li>Optimization</li>
<li>Implementation (hardware)</li>
</ul></li>
<li>Differen NN Architectures</li>
</ul>
</section>
<section id="thanks" class="slide level2 scrollable">
<h2 class="scrollable">Thanks!</h2>
<ul>
<li><p>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></p></li>
<li><p>podcast: <a href="http://thetalkingmachines.com">The Talking Machines</a></p></li>
<li><p>newspaper: <a href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile Page</a></p></li>
<li><p>blog posts:</p>
<p><a href="http://inverseprobability.com/2017/07/17/what-is-machine-learning">What is Machine Learning?</a></p></li>
</ul>
</section>
<section id="references" class="slide level2 unnumbered scrollable">
<h2 class="unnumbered scrollable">References</h2>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-Boser-optimal92">
<p>Boser, B.E., Guyon, I.M., Vapnik, V.N., 1992. A training algorithm for optimal margin classifiers, in: Proceedings of the Fifth Annual Workshop on Computational Learning Theory, COLT ’92. Association for Computing Machinery, New York, NY, USA, pp. 144–152. <a href="https://doi.org/10.1145/130385.130401">https://doi.org/10.1145/130385.130401</a></p>
</div>
<div id="ref-Cortes:svnet95">
<p>Cortes, C., Vapnik, V.N., 1995. Support vector networks. Machine Learning 20, 273–297. <a href="https://doi.org/10.1007/BF00994018">https://doi.org/10.1007/BF00994018</a></p>
</div>
<div id="ref-LeCun:zip89">
<p>Le Cun, Y., Boser, B.E., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D., 1989. Backpropagation applied to handwritten zip code recognition. Neural Computation 1, 541–551. <a href="https://doi.org/10.1162/neco.1989.1.4.541">https://doi.org/10.1162/neco.1989.1.4.541</a></p>
</div>
<div id="ref-Rumelhart:book86">
<p>Rumelhart, D.E., McClelland, J.L., the PDP Research Group, 1986. Parallel distributed programming: Explorations in the microstructure of cognition. mit, Cambridge, MA.</p>
</div>
</div>
</section>
    </div>
  </div>

  <script src="reveal.js/lib/js/head.min.js"></script>
  <script src="reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
        // Transition style
        transition: 'None', // none/fade/slide/convex/concave/zoom
        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/math/math.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
