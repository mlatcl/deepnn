---
layout: lecture
title: Generalization and Neural Networks
week: 1
session: 2
date: 2021-01-26
author:
- given: Neil D.
  family: Lawrence
  institution: University of Cambridge
  url: http://inverseprobability.com
abstract: >
  This lecture will cover generalization in machine learning with a particular focus on
  neural architectures. We will review classical generalization and explore what's different
  about neural network models.
talkscam:
reveal: False
ipynb: False
time: "14:00"
start: "14:00"
end: "15:00"
---

\include{talk-macros.gpp}

\include{_deepnn/includes/deepnn-notebook-setup.md}
\include{_ml/includes/linear-regression-direct-solution.md}
\include{_ml/includes/bias-variance-dilemma.md}
\include{_ml/includes/bias-variance-dilemma.md}
\include{_ml/includes/double-descent.md}

\thanks

\references


Bias variance dilemma <https://www.mitpressjournals.org/doi/abs/10.1162/neco.1992.4.1.1>

bootstrap


Bootstrap Predication and Bayesian Misspecified Models: <https://www.jstor.org/stable/3318894#metadata_info_tab_contents>

Edwin Fong and Chris Holmes: On the Marginal Likelihood and Cross Validation <https://arxiv.org/abs/1905.08737>


The lack of a priori distinction between learning algorithms (No free lunch)
<https://www.mitpressjournals.org/doi/abs/10.1162/neco.1996.8.7.1341>
<https://link.springer.com/chapter/10.1007/978-1-4471-0123-9_3>


David Hogg's lecture <https://speakerdeck.com/dwhgg/linear-regression-with-huge-numbers-of-parameters>


Belkin on Bias/Variance
<https://www.pnas.org/content/116/32/15849.short>
<https://www.pnas.org/content/117/20/10625>

Belkin Talk: <http://www.ipam.ucla.edu/abstract/?tid=15552&pcode=GLWS4>

The Deep Bootstrap <https://twitter.com/PreetumNakkiran/status/1318007088321335297?s=20>

Aki Vehtari on Leave One Out Uncertainty: <https://arxiv.org/abs/2008.10296> (check for his references).

Large models and memorisation: <https://arxiv.org/abs/2012.07805>



